# -*- coding: utf-8 -*-
"""GV_LLMquery.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MZ1LqIwXtm7NlpKqh28Gyf_KM44IWdUG
"""

# !pip install -q openai owlready2 rdflib sentence-transformers faiss-cpu

# from google.colab import userdata
from openai import OpenAI
from owlready2 import *
import json
from dotenv import load_dotenv
import os
import faiss
import types
import json
import numpy as np
from sentence_transformers import SentenceTransformer
# ontology_path = "/content/VIPRIME.owl"
# onto = get_ontology(ontology_path).load()
load_dotenv(dotenv_path="secrect.env")
OPENAI_API_KEY= os.getenv('OPENAI_API_KEY')
client = OpenAI(api_key = OPENAI_API_KEY)

ontology_path = "static/VIPRIME.owl"
name_ontology = ontology_path.split('/')[-1].split('.')[0]
onto = get_ontology(ontology_path).load()

model_embedding = SentenceTransformer("model_embedding")

"""**pp1**: lấy toàn bộ anotation làm chú thích
**pp2**: embedding anotation để tìm gần với câu hỏi và lấy entity đó

**Tìm tất cả các instances có anotation**
"""

def get_entities_with_annotation(onto, annotation):
    """
    Tìm tất cả các instances và classes có annotation trong ontology.

    Parameters:
    - onto: Ontology đang làm việc
    - annotation: Tên annotation cần tìm

    Returns:
    - Dictionary chứa tất cả các instances và classes có annotation
    """
    result = {}
    processed_entities = set()  # Tập hợp để theo dõi các entity đã xử lý

    # Duyệt qua tất cả các lớp trong ontology
    for cls in onto.classes():
        # Kiểm tra và thêm annotation của class (nếu có và chưa xử lý)
        if cls.name not in processed_entities and hasattr(cls, annotation):
            annotation_value = getattr(cls, annotation)
            if annotation_value:  # Kiểm tra không rỗng
                # Loại bỏ các giá trị trùng lặp trong annotation_value nếu nó là list
                if isinstance(annotation_value, list):
                    # Sử dụng dict.fromkeys để loại bỏ các phần tử trùng lặp nhưng giữ thứ tự
                    unique_values = list(dict.fromkeys(tuple(x) if isinstance(x, list) else x for x in annotation_value))
                    result[cls.name] = {annotation: unique_values}
                else:
                    result[cls.name] = {annotation: annotation_value}
                processed_entities.add(cls.name)

        # Xử lý các instances
        for instance in cls.instances():
            if instance.name not in processed_entities and hasattr(instance, annotation):
                annotation_value = getattr(instance, annotation)
                if annotation_value:
                    # Loại bỏ các giá trị trùng lặp trong annotation_value nếu nó là list
                    if isinstance(annotation_value, list):
                        # Chuyển đổi các phần tử để có thể so sánh và loại bỏ trùng lặp
                        unique_values = list(dict.fromkeys(tuple(x) if isinstance(x, list) else x for x in annotation_value))
                        result[instance.name] = {annotation: unique_values}
                    else:
                        result[instance.name] = {annotation: annotation_value}
                    processed_entities.add(instance.name)
    return result

# Ví dụ sử dụng
# s_time = time.time()
# entities_with_annotation = get_entities_with_annotation(onto, "thong_tin")
# e_time = time.time()
# print(f"Số lượng entities có annotation thong_tin: {len(entities_with_annotation)}")
# print(f"Thời gian chạy: {e_time - s_time}s")
# print(entities_with_annotation)
# # In kết quả đẹp chi tiết dưới dạng cây (type = string)
# import json
# print(json.dumps(entities_with_annotation, indent=4, ensure_ascii=False))

"""Thêm annotation mới"""


def safe_add_annotation_property(onto, annotation_name):
    """Tạo annotation property nếu chưa tồn tại."""
    with onto:
        if not hasattr(onto, annotation_name):
            print(f"Tạo annotation property mới: {annotation_name}")
            NewAnnotation = types.new_class(annotation_name, (AnnotationProperty,))
            setattr(onto, annotation_name, NewAnnotation)

def add_annotation_to_entity(onto, entity_name, annotation_name, annotation_value, save_path=None, save_ontology=False):
    """Thêm annotation cho một entity trong ontology."""
    try:
        entity = onto[entity_name]  # Lấy entity từ ontology
        safe_add_annotation_property(onto, annotation_name)

        # GÁN TRỰC TIẾP GIÁ TRỊ (Không append!)
        setattr(entity, annotation_name, annotation_value)

        # Lưu ontology nếu cần
        if save_ontology:
            save_target = save_path if save_path else "/content/VIPRIME.owl"
            onto.save(file=save_target, format="rdfxml")
            print(f"Đã lưu ontology tại {save_target}.")

        print(f"Đã thêm annotation '{annotation_name}' với giá trị '{annotation_value}' cho entity '{entity_name}'.")

    except KeyError:
        print(f"Entity '{entity_name}' không tồn tại trong ontology.")

"""LLM tóm tắt"""

def LLM_summary(text_for_summary):
    system_prompt = '''
        Bạn là chuyên gia trong lĩnh vực tóm tắt các văn bản liên quan đến chủ di sản văn hóa.
        YÊU CẦU:
        - Tóm tắt ngắn gọn nhất có thể các văn bản nhưng vẫn phải giữ lại các thông tin đặc trưng về di sản văn hóa.
        - Chỉ trả về văn bản tóm tắt, không được nói gì thêm.
    '''
    response = client.chat.completions.create(
        model='gpt-4o-mini',
        temperature=0,
        messages=[
            {
                "role": "system",
                "content": system_prompt
            },
            {
                "role": "user",
                "content": text_for_summary
            }
        ]
    )
    return response.choices[0].message.content

"""Embeddings"""


def save_embeddings_numpy(data: dict, save_dir="saved_embeddings"):
    """
    Lưu embeddings thành file numpy (npy) để load nhanh qua memory map.

    Args:
        data (dict):
            {
                entity_name: {
                    'all_info_embedding': vector,
                    'summary_embedding': vector
                }
            }
        save_dir (str): thư mục để lưu files
    """
    os.makedirs(save_dir, exist_ok=True)

    entity_names = list(data.keys())
    all_info_vectors = []
    summary_vectors = []

    for entity in entity_names:
        all_info_vectors.append(data[entity]["all_info_embedding"])
        summary_vectors.append(data[entity]["summary_embedding"])

    # Convert thành numpy array
    all_info_vectors = np.array(all_info_vectors, dtype=np.float32)
    summary_vectors = np.array(summary_vectors, dtype=np.float32)

    # Lưu vector
    np.save(os.path.join(save_dir, "all_info_embeddings.npy"), all_info_vectors)
    np.save(os.path.join(save_dir, "summary_embeddings.npy"), summary_vectors)

    # Lưu entity name mapping
    with open(os.path.join(save_dir, "entity_names.json"), "w") as f:
        json.dump(entity_names, f)

    print(f"Đã lưu {len(entity_names)} embeddings dưới dạng numpy.")

"""Thêm tóm tắt cho toàn ontology. **Chỉ thực hiện 1 lần**"""

def add_new_annotation_value_for_ontology(dict_entities_with_annotation : dict, model_embedding):
    is_end_of_items = False
    for i, (entity, entity_value) in enumerate(dict_entities_with_annotation.items()):
        if i == len(dict_entities_with_annotation) - 1:  # Kiểm tra xem có phải phần tử cuối cùng không
            is_end_of_items = True
        print(entity)
        for annotation, value in entity_value.items():
            full_text_information = ''.join(value)
            summary = LLM_summary(full_text_information)
            add_annotation_to_entity(onto, entity, 'tom_tat', summary, save_ontology = is_end_of_items)

            all_info_embedding = model_embedding.encode(full_text_information, normalize_embeddings=True)
            add_annotation_to_entity(onto, entity, 'all_info_embeddings', all_info_embedding.tolist(), save_ontology = is_end_of_items)
            summary_embedding = model_embedding.encode(summary, normalize_embeddings=True)
            add_annotation_to_entity(onto, entity, 'summary_embeddings', summary_embedding.tolist(), save_ontology = is_end_of_items)

"""Load Embeddings"""

def load_embeddings_from_ontology(onto, annotation_raw_info_name, annotation_embeddings_name):
    """
    Tải embeddings từ annotation trong ontology và tạo FAISS index.

    Args:
        onto: Ontology đang làm việc
        annotation_embeddings_name: Tên annotation chứa embedding
        annotation_raw_info_name: Tên annotation chứa thông tin ban đầu

    Returns:
        tuple: (index, entity_names)
    """
    print("Đang tải embeddings từ ontology...")

    # Lấy tất cả entity có annotation chứa embedding
    entities_with_embeddings = get_entities_with_annotation(onto, annotation_embeddings_name)
    raw_info_entities = get_entities_with_annotation(onto, annotation_raw_info_name)

    if not entities_with_embeddings:
        raise ValueError(f"Không tìm thấy entity nào có annotation '{annotation_embeddings_name}'")

    entity_names = []
    raw_informations = []
    embeddings_list = []

    for entity_name, annotations in entities_with_embeddings.items():
        embedding_value = annotations[annotation_embeddings_name]

        # Nếu embedding là list lồng (ví dụ [[0.1, 0.2, 0.3]]), lấy phần tử đầu tiên
        if isinstance(embedding_value, list) and isinstance(embedding_value[0], (list, tuple)):
            embedding_value = embedding_value[0]

        # Đảm bảo kiểu numpy array float32
        embedding_array = np.array(embedding_value, dtype=np.float32)

        embeddings_list.append(embedding_array)
        entity_names.append(entity_name)

    # Stack thành ma trận embeddings
    embeddings = np.vstack(embeddings_list)

    for entity_name, annotations in raw_info_entities.items():
        raw_information = annotations[annotation_raw_info_name]
        text_raw_information = ''.join(raw_information)
        raw_informations.append(text_raw_information)

    # Tạo FAISS index
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)  # Inner Product (dot product), cần normalize nếu cosine
    index.add(embeddings)

    print(f"Đã tải {len(entity_names)} entity với embedding, dimension={dimension}")
    return index, entity_names, raw_informations

def find_similar_info_from_index(question, model_embedding, index, entity_names, raw_informations, k=5):
    """
    Tìm k thông tin gần nhất với câu hỏi dựa trên FAISS index đã có.

    Args:
        question (str): Câu hỏi cần tìm kiếm
        model_embedding (SentenceTransformer): Model embedding đã nạp
        index (faiss.IndexFlatIP): FAISS index đã load sẵn
        entity_names (list): Danh sách tên entity tương ứng với index
        k (int): Số lượng kết quả muốn tìm

    Returns:
        tuple: (k_idx_info, k_similar_info)
    """
    # Encode câu hỏi thành embedding
    question_embedding = model_embedding.encode([question], normalize_embeddings=True)
    query_embedding = np.array(question_embedding, dtype=np.float32)

    # Tìm kiếm trong index
    distances, indices = index.search(query_embedding, k)

    k_idx_info = []
    k_similar_info = []
    k_entity_names = []
    for idx in indices[0]:
        k_idx_info.append(idx)
        if raw_informations != None:
            k_similar_info.append(raw_informations[idx])
        k_entity_names.append(entity_names[idx])

    return k_idx_info, k_similar_info, k_entity_names

"""**===========================================================**

**Find_relation()**
"""

def find_relation(onto):
    """
    Tìm cấu trúc cây phân cấp của ontology và các instances.

    Parameters:
    - onto: Ontology đang làm việc

    Returns:
    - Dictionary chứa cấu trúc cây ontology
    """
    result = {}

    # Danh sách tất cả các lớp để kiểm tra
    all_classes = list(onto.classes())
    # Tìm các top-level classes (không có superclass ngoài Thing)
    top_classes = []
    for cls in all_classes:
        # Lấy tất cả các lớp cha trực tiếp
        parents = [p for p in cls.is_a if isinstance(p, onto.Thing.__class__)]
        # Loại bỏ Thing hoặc lớp chính nó
        parents = [p for p in parents if p != onto.Thing and p != cls]

        if not parents:  # Nếu không có lớp cha nào ngoài Thing
            top_classes.append(cls)
    def build_tree(cls):
        try:
          label = cls.label[0]
          if label:
            node_name = label
          else:
            node_name = cls.name
        except:
          node_name = cls.name
        """Xây dựng cây cho một lớp cụ thể"""
        node = {"name": node_name}

        # Tìm tất cả lớp con trực tiếp
        direct_subclasses = []
        for sub in all_classes:
            if cls in sub.is_a and sub != cls:
                direct_subclasses.append(sub)

        if direct_subclasses:  # Nếu có lớp con
            node["subclasses"] = []
            for sub in direct_subclasses:
                node["subclasses"].append(build_tree(sub))
        else:  # Nếu là lớp lá (không có lớp con)
            # Tìm instances của lớp này
            instances = list(cls.instances())
            if instances:
                node["Instances"] = [inst.name for inst in instances]
        return node

    for cls in top_classes:
        result[cls.name] = build_tree(cls)

    return result
# rs = find_relation(onto)
# print(json.dumps(rs, indent=4, ensure_ascii= False))

"""**PP0: chỉ lấy mối quan hệ để LLM tìm entities**"""

def find_entities_from_question_PP0( relation, question):
  system_prompt = f'''
        Bạn là một agent hữu ích được thiết kế để tìm thông tin từ cơ sở dữ liệu ontology.
        Cơ sở dữ liệu ontology về các dòng nhạc có các quan hệ sau:
        {json.dumps(relation, indent=4, ensure_ascii= False)}

        Yêu cầu:
        Tùy thuộc vào câu hỏi người dùng, xác định xem có thể trả lời với cơ sở dữ liệu ontology không.
        Tìm ra các thực thể có trong câu hỏi người dùng hoặc các thực thể phù hợp có khả năng trả lời cho câu hỏi dựa trên các quan hệ.

        Kết quả:
        Trả về kết quả là các class dưới dạng JSON có dạng sau:
        {{
            "(parent_class)": [(các thực thể tìm ra được trong câu hỏi)]
        }}
        Trong đó: parent_class BẮT BUỘC chỉ chọn 1 trong 2 phần tử sau:
        "Dong_nhac", "Tinh_thanh"

        Ví dụ đầu vào:
        "Nhạc cung đình Huế xuất hiện vào khoảng thời gian nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{
            "Dong_nhac" : ["Nhac_cung_dinh"]
        }}
        Ví dụ đầu vào:
        "Dân ca bao gồm các loại những loại nhạc nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{
            "Dong_nhac" : ["Dan_ca"]
        }}
        Ví dụ đầu vào:
        "Bắc Giang có những di sản nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{  "Dong_nhac" : ["Ca_tru", "Dan_ca"],
            "Tinh_thanh" : ["Bac_giang"]
        }}

        Ví dụ đầu vào:
        "Đờn ca tài tử là gì và nó có mặt ở các tỉnh thành nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{  "Dong_nhac" : ["Nhac_tai_tu"],
            "Tinh_thanh" : ["Vinh_long","An_giang","Ben_tre"]
        }}

        Nếu không có thực thể liên quan trong câu hỏi người dùng hoặc câu hỏi không liên quan đến các di sản hãy trả về một đối tượng JSON trống có dạng như sau:
        {{
            "Trong": []
        }}
  '''
  response = client.chat.completions.create(
      model='gpt-4o-mini',
      temperature=0,
      messages=[
          {
              "role": "system",
              "content": system_prompt
          },
          {
              "role": "user",
              "content": question
          }
          ]
    )
  return response.choices[0].message.content

"""**PP1: lấy toàn bộ anotation làm chú thích và để LLM tìm trên chú thích (nếu có)**"""

def create_explication(entities_with_annotation_sumarry : dict):
  explication = {}
  for entity, entity_value in entities_with_annotation_sumarry.items():
    for annotation, value in entity_value.items():
        full_text_information = ''.join(value)
        explication[entity] = full_text_information
  return explication

def find_entities_from_question_PP1(relation, explication, question):
  system_prompt = f'''
        Bạn là một agent hữu ích được thiết kế để tìm thông tin từ cơ sở dữ liệu ontology.
        Cơ sở dữ liệu ontology về các dòng nhạc có các quan hệ sau:
        {json.dumps(relation, indent=4, ensure_ascii= False)}
        Thông tin chú thích:
        {json.dumps(explication, indent=4, ensure_ascii= False)}

        Yêu cầu:
        Tùy thuộc vào câu hỏi người dùng, xác định xem có thể trả lời với cơ sở dữ liệu ontology không.
        Tìm ra các thực thể có trong câu hỏi người dùng hoặc các thực thể phù hợp có khả năng trả lời cho câu hỏi dựa trên các quan hệ và thông tin chú thích.

        Kết quả:
        Trả về kết quả là các class dưới dạng JSON có dạng sau:
        {{
            "(parent_class)": [(các thực thể tìm ra được trong câu hỏi)]
        }}
        Trong đó: parent_class BẮT BUỘC chỉ chọn 1 trong 2 phần tử sau:
        "Dong_nhac", "Tinh_thanh"

        Ví dụ đầu vào:
        "Nhạc cung đình Huế xuất hiện vào khoảng thời gian nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{
            "Dong_nhac" : ["Nhac_cung_dinh"]
        }}
        Ví dụ đầu vào:
        "Dân ca bao gồm các loại những loại nhạc nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{
            "Dong_nhac" : ["Dan_ca"]
        }}
        Ví dụ đầu vào:
        "Bắc Giang có những di sản nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{  "Dong_nhac" : ["Ca_tru", "Dan_ca"],
            "Tinh_thanh" : ["Bac_giang"]
        }}

        Ví dụ đầu vào:
        "Đờn ca tài tử là gì và nó có mặt ở các tỉnh thành nào?"
        Đầu ra dự kiến ​​sẽ là:
        {{  "Dong_nhac" : ["Nhac_tai_tu"],
            "Tinh_thanh" : ["Vinh_long","An_giang","Ben_tre"]
        }}

        Nếu không có thực thể liên quan trong câu hỏi người dùng hoặc câu hỏi không liên quan đến các di sản hãy trả về một đối tượng JSON trống có dạng như sau:
        {{
            "Trong": []
        }}
  '''
  response = client.chat.completions.create(
      model='gpt-4o-mini',
      temperature=0,
      messages=[
          {
              "role": "system",
              "content": system_prompt
          },
          {
              "role": "user",
              "content": question
          }
          ]
    )
  return response.choices[0].message.content

"""**pp2: embedding anotation để tìm gần với câu hỏi và lấy entity đó**"""

def classify_entities(onto, entity_names, root_classes=("Dong_nhac", "Tinh_thanh")):
    """
    Phân loại entity theo 2 class cha lớn nhất: Dong_nhac và Tinh_thanh.

    Args:
        entity_names: List tên các entity cần phân loại
        onto: Ontology đang làm việc
        root_classes: Tuple chứa tên các class gốc

    Returns:
        dict: {class cha: [các entity con]}
    """
    classification = {root: [] for root in root_classes}

    # Tìm object class gốc
    root_class_objs = {root: onto.search_one(iri="*" + root) for root in root_classes}

    for name in entity_names:
        entity = onto.search_one(iri="*" + name)
        if entity is None:
            print(f"[!] Không tìm thấy '{name}' trong ontology.")
            continue

        # Nếu là Class
        if isinstance(entity, ThingClass):
            parent_classes = list(entity.ancestors())
        else:
            # Nếu là individual → lấy type (các class mà nó là instance)
            parent_classes = []
            for cls in entity.is_a:
                if isinstance(cls, ThingClass):
                    parent_classes.extend(cls.ancestors())

        # Kiểm tra xem entity thuộc root class nào
        matched = False
        for root, root_obj in root_class_objs.items():
            if root_obj in parent_classes:
                classification[root].append(name)
                matched = True
                break

        if not matched:
            print(f"[!] '{name}' không thuộc class nào trong {root_classes}.")

    return classification

def find_entities_from_question_PP2(ontology, model_embedding):
    '''
    ouput:
      k_entity_names: list các entity có trong câu hỏi
    '''
    index, entity_names, raw_inforamtions = load_embeddings_from_ontology(ontology,'tom_tat','summary_embeddings')
    k_idx_info, k_similar_info, k_entity_names = find_similar_info_from_index(
        question="Việt Nam có những loại hình dân ca nào?",
        model_embedding=model_embedding,
        index=index,
        entity_names = entity_names,
        raw_informations = raw_inforamtions,
        k=5
    )

    return k_entity_names

def get_direct_class_of_individual(onto, individual_name):
    """
    Trả về class cha trực tiếp đầu tiên (rdf:type) của một individual.

    Args:
        onto: Ontology đã load bằng Owlready2.
        individual_name (str): Tên của individual trong ontology.

    Returns:
        str hoặc None: Tên class cha trực tiếp, hoặc None nếu không có.
    """
    try:
        individual = onto[individual_name]
        if individual and individual.is_a:
            return individual.is_a[0].name  # Trả về tên class cha trực tiếp đầu tiên
        else:
            return None
    except Exception as e:
        print(f"[!] Lỗi khi truy xuất class cha của individual '{individual_name}': {e}")
        return None

def query_all(name_ontology, query_all_class_info, value):
      prefix = '''
        PREFIX owl: <http://www.w3.org/2002/07/owl#>
        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
        PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
        PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
        PREFIX viprime: <http://www.semanticweb.org/tranh/ontologies/2023/9/viprime#>
      '''
      query1 = ''
      query1 = query1 + f''' SELECT DISTINCT  ?class ?pre ?preVal
                            WHERE {{
                                  BIND(viprime:{str(value).replace(f"{name_ontology}.",'')} AS ?class).
                                  ?class ?pre ?preVal.
                            }}
                        '''
      query_all_class_info.append(prefix + query1)
      query2 = f''' SELECT DISTINCT  ?individual  ?predicate  ?value
                    WHERE {{
                        {{
                            SELECT ?individual
                            WHERE {{ ?individual rdf:type viprime:{str(value).replace(f"{name_ontology}.",'')}. }}
                            LIMIT 1
                        }}
                        ?individual ?predicate ?value.
                        ?predicate rdf:type owl:ObjectProperty.
                    }}
      '''
      query_all_class_info.append(prefix + query2)

# def create_query(name_ontology, json_data):
#     query_all_class_info = []
#     for value in json_data['Dong_nhac']:
#         entities = []
#         if onto.get_children_of(onto[value]):
#             query_all(name_ontology, query_all_class_info,value)
#             entities = onto.get_children_of(onto[value])
#             for entity in entities:
#                 query_all(name_ontology, query_all_class_info,entity)
#         else:
#           query_all(name_ontology, query_all_class_info,onto[value])
#     return query_all_class_info
def create_query(name_ontology, json_data):
    """
    Tổng quát hóa hàm tạo query từ ontology dựa trên json_data.

    Args:
        name_ontology: Tên ontology đang làm việc
        json_data: Dữ liệu JSON chứa các key và list các entity cần truy vấn

    Returns:
        list: Tất cả thông tin truy vấn được
    """
    query_all_class_info = []

    for key, values in json_data.items():
        has_class_parent = False
        set_class_parent = set()
        if key == "Trong":
            continue  # Bỏ qua nếu key là 'Trong'

        for value in values:
            # Lấy thực thể từ ontology
            entity = onto.search_one(iri="*" + value)
            if entity is None:
                print(f"[!] Không tìm thấy '{value}' trong ontology.")
                continue

            # Nếu là class, xử lý bình thường
            if isinstance(entity, ThingClass):
                children = onto.get_children_of(entity)

                query_all(name_ontology, query_all_class_info, entity)
                for child in children:
                    query_all(name_ontology, query_all_class_info, child)
            # Nếu là individual
            else:
                class_parent = get_direct_class_of_individual(onto, value)
                set_class_parent.add(class_parent)
                has_class_parent = True
        if has_class_parent:
            for class_parent in set_class_parent:
                query_all(name_ontology, query_all_class_info, class_parent)

    return query_all_class_info

def find_question_info(name_ontology, list_query):
    """
    Chạy danh sách SPARQL query và trích xuất kết quả ra dạng text dễ đọc.

    Args:
        name_ontology: Tên ontology (dùng để bỏ prefix khi cần)
        list_query: List query SPARQL cần thực thi

    Returns:
        list: Các kết quả đã tiền xử lý (list of list)
    """
    results = []

    for query in list_query:
        try:
            query_result = list(default_world.sparql_query(query))
        except Exception as e:
            print(f"[!] Lỗi khi thực thi query: {e}")
            continue

        for record in query_result:
            information = []
            for val in record:
                processed_text = ""

                # Nếu có label thì ưu tiên lấy label
                if hasattr(val, "label") and val.label:
                    processed_text = str(val.label[0])
                else:
                    # Nếu không có label, thì xử lý text bình thường
                    processed_text = str(val)
                    if processed_text.startswith(f"{name_ontology}."):
                        processed_text = processed_text.replace(f"{name_ontology}.", "")

                    # Xử lý đặc biệt nếu cần (ví dụ trường hợp '9' bạn từng gặp)
                    if processed_text == '9':
                        processed_text = 'Là con của'

                information.append(processed_text)

            results.append(information)

    return results

def generate_response(relationship ,question_info, question, history ):
  system_prompt  = f'''
            Bạn là một agent hữu ích giúp trả lời câu hỏi của người dùng dựa trên thông tin được cung cấp.
            Đồng thời, dựa vào lịch sử cuộc trò chuyện để hiểu rõ hơn ngữ cảnh cuộc trò chuyện.
            THÔNG TIN:

            {question_info}

            LỊCH SỬ CUỘC TRÒ CHUYỆN:

            {history}

            Nếu không có câu trả lời, hãy nói: Tôi không biết, tôi chưa có kiến thức để trả lời câu hỏi này.
  '''
  response = client.chat.completions.create(
      model='gpt-4o-mini',
      temperature=0,
      messages=[
          {
              "role": "system",
              "content": system_prompt
          },
          {
              "role": "user",
              "content": question
          }
          ]
      )
  return response.choices[0].message.content

def find_url(name_ontology, json_data, n_video = 3):
    url_results = []
    queries = []
    video_info = '''
              PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
              PREFIX owl: <http://www.w3.org/2002/07/owl#>
              PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>
              PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>
              PREFIX viprime:<http://www.semanticweb.org/tranh/ontologies/2023/9/viprime#>
              SELECT ?individual ?predicate ?value
              WHERE {{
                    {{
                      SELECT DISTINCT ?individual
                      WHERE {{ ?individual rdf:type viprime:{entity}. }}
                      ORDER BY RAND()
                      LIMIT {n_video}
                  }}
                  ?individual ?predicate ?value.

                  FILTER (isLiteral(?value))
              }}'''
    try:
        for value in json_data['Dong_nhac']:
            entities = []
            if onto.get_children_of(onto[value]):
                entities = onto.get_children_of(onto[value])
                for entity in entities:
                    queries.append(video_info.format(entity = str(entity).replace(f"{name_ontology}.", ""), n_video = n_video))
            else:
                queries.append(video_info.format(entity = str(value).replace(f"{name_ontology}.", ""), n_video = n_video))

            video_url = find_question_info(name_ontology, queries)
            for info in video_url:
                if 'có url là' in " ".join(info):
                    url_results.append(info[2])
    except:
        return []

    return url_results

def find_similar_info_from_raw_informations(question, result_from_ontology, k = 5):
    info_sentences = [" ".join(triple) for triple in result_from_ontology]

    embeddings = model_embedding.encode(info_sentences, normalize_embeddings=True)
    sentences_embeddings = np.array(embeddings, dtype=np.float32)

    dimension = embeddings.shape[1]
    index = faiss.IndexFlatIP(dimension)
    index.add(sentences_embeddings)

    similar_info = []

    question_embedding = model_embedding.encode([question], normalize_embeddings=True)
    query_embedding = np.array(question_embedding, dtype=np.float32)

    distances, indices = index.search(query_embedding, k)
    for idx in indices[0]:
        similar_info.append(info_sentences[idx])
    return similar_info


# # Phuong phap 1: tim anotation thong tin lam chu thich cho instance
# history = ''
# question = 'Đờn ca tài tử có mặt chủ yếu ở vùng miền nào của nước ta'

# relation = find_relation(onto)
# print("======================ENTITIES======================================")
# # Phương pháp 0
# # entities = find_entities_from_question_PP0(relation,question)
# # print(entities)

# # Phương pháp 1:
# # entities_with_annotation_sumarry = get_entities_with_annotation(onto, 'tom_tat')
# # explication = create_explication(entities_with_annotation_sumarry)
# # entities = find_entities_from_question_PP1(relation,explication,question)
# # print(entities)

# # Phương pháp 2:
# k_entity_names = find_entities_from_question_PP2(onto, model_embedding)
# print(k_entity_names)
# entities = classify_entities(onto, k_entity_names)
# print(entities)
# entities = json.dumps(entities)

# list_query = create_query(name_ontology, json.loads(entities) )
# list_url = find_url(name_ontology, json.loads(entities))
# print("\n======================KẾT QUẢ TRA CỨU===================================\n")
# result_from_ontology = find_question_info(name_ontology, list_query)

# raw_informations_from_ontology = []
# for result in result_from_ontology:
#   if str(result[1]) not in ["all_info_embeddings", "summary_embeddings"]:
#     print(result)
#     raw_informations_from_ontology.append(result)

# k_similar_info = find_similar_info_from_raw_informations(question, raw_informations_from_ontology)
# print("\n======================SIMILAR INFO======================================\n")
# print(k_similar_info)
# response = generate_response(relation , k_similar_info, question, history)
# print("\n======================CÂU TRẢ LỜI=======================================\n")
# print(response)
# print(list_url)